# msa-transformer
Repository for the ***Machine Learning*** course project, involving the use of transformers for the study of MSA for prediction of contact maps.

This is a simple and personal of **MSA Transformer** [link](http://proceedings.mlr.press/v139/rao21a/rao21a.pdf), using self-attention and techniques like Axial Attention and Tied Attention to reduce the memory cost of the computation.

![Screenshot from 2023-02-19 10-28-41](https://user-images.githubusercontent.com/54988047/219939935-38b6a516-5d77-4e91-86fd-c0c18975998d.png)

