{
    "epochs": 100,
    "batch_size": 1,
    "learning_rate": 0.0001,
    "scheduling": 0,
    "alphabet_size": 21,
    "max_sequences": 32,
    "max_positions": 256,
    "mask_prob": 0.2,
    "layers": 12,
    "embed_dim": 384,
    "bias": false,
    "ffn_embedding_dim": 768,
    "attention_heads": 6,
    "dropout": 0.1,
    "attention_dropout": 0.1,
    "activation_dropout": 0.1,
    "max_tokens": 16384
}